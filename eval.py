# -*- coding: utf-8 -*-
"""AI Summer SimCLR Resnet18 STL10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LhKx8FPwn8GvLbiaOp3m2wZOPZE44tgZ

# SimCLR in STL10 with Resnet18 AI Summer tutorial

## Imports, basic utils, augmentations and Contrastive loss
"""
from typing import Any, Optional
import pandas as pd
from pytorch_lightning.utilities.types import STEP_OUTPUT
import torch
import numpy as np

from torchvision import transforms as T


from torch.multiprocessing import cpu_count

from simclr import SimCLR_pl

"""## Pretraining main logic"""
from pytorch_lightning import Trainer
from pytorch_lightning import seed_everything
from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor
from torchvision.models import  resnet18

from dataset import MIMIC_CXR_Dataset
from torch.utils.data import DataLoader
from pytorch_lightning import LightningModule

from simclr import SimCLRTestTransforms, SimCLRTrainTransforms
from tqdm import tqdm

from barlow_twins import BarlowTwins
from byol import BYOL
from simsiam import SimSiam

from eval_loader import Prompt_Set, OOD_Loader

from pytorch_msssim import ms_ssim

# ROOT = '/home/asim.ukaye/physionet.org/files/mimic-cxr-jpg/2.0.0/'

ROOT = '/home/asim.ukaye/ml_proj/mimic_cxr_pa_resized/'
ROOT_PROMPT = '/l/users/mohammed.qazi/'

# METHOD = 'simclr'
# METHOD = 'barlow'
# METHOD = 'simsiam'
# METHOD = 'byol'
METHOD = 'mssim'

# Original original
# PHASE = 'og-og'

# Original transforms
# PHASE = 'og-ot'

# # Original Prompt
# PHASE = 'og-pr'

# # Intra Prompt
# PHASE = 'pr-pr'

# # Inter Prompt
PHASE = 'pr-qr'

# # OOD
# PHASE = 'og-xd'

# OUT_NAME = ''


EPOCHS = 1000
BATCH_SIZE = 64
NUM_WORKERS = 24

CKPT_LOAD = True


print("Running method: ", METHOD)
print("Running phase: ", PHASE)


# SImCLR PAth
if METHOD == 'simclr':
    CKPT_PATH ='/home/asim.ukaye/ml_proj/simclr_cxr/lightning_logs/version_38/checkpoints/last.ckpt'
elif METHOD == 'barlow':
# BArlow checkpoint
    CKPT_PATH ='/home/asim.ukaye/ml_proj/simclr_cxr/lightning_logs/version_36/checkpoints/last.ckpt'
elif METHOD == 'byol':
# BArlow checkpoint
    CKPT_PATH ='/home/asim.ukaye/ml_proj/simclr_cxr/lightning_logs/version_35/checkpoints/last.ckpt'
elif METHOD == 'simsiam':
# BArlow checkpoint
    CKPT_PATH ='/home/asim.ukaye/ml_proj/simclr_cxr/lightning_logs/version_37/checkpoints/last.ckpt'


# 

seed_everything(1256)

# dm = CXR_DataModule(ROOT, BATCH_SIZE, mode='train')
if METHOD == 'mssim':
    transforms= None
else: 
    transforms = T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),


if PHASE == 'og-og':
    transforms = SimCLRTestTransforms(224)
    all_set = MIMIC_CXR_Dataset(ROOT, split='train', augmentations=transforms)
if PHASE == 'og-ot':
    transforms = SimCLRTrainTransforms(img_size=224)
    all_set = MIMIC_CXR_Dataset(ROOT, split='train', augmentations=transforms)

if PHASE == 'og-pr':
    all_set = Prompt_Set(ROOT, ROOT_PROMPT, mode='og-prompt', augmentations=transforms)
if PHASE == 'pr-pr':
    all_set = Prompt_Set(ROOT, ROOT_PROMPT, mode='intra-prompt',augmentations=transforms)
if PHASE == 'pr-qr':
    all_set = Prompt_Set(ROOT, ROOT_PROMPT, mode='inter-prompt',  augmentations=transforms)
if PHASE == 'og-xd':
    all_set = OOD_Loader(ROOT, split='train' , mode='ood', augmentations=transforms)



# transforms = None
# train_set = MIMIC_CXR_Dataset(ROOT, split='train',augmentations=transforms)
# val_set = MIMIC_CXR_Dataset(ROOT, split='val', augmentations=transforms)
# test_set = MIMIC_CXR_Dataset(ROOT, split='test', augmentations=transforms)
# []

# all_set = MIMIC_CXR_Dataset(ROOT, split='train', augmentations=transforms)





# train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)
# val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)
# test_loader = DataLoader(test_set,  batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)

all_loader = DataLoader(all_set,  batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)

# all_loader = DataLoader(test_set,  batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)


class MSSSIM_Module(LightningModule):
    def __init__(self, batch_size,):
        super().__init__()

        self.batch_size = batch_size
    def test_step(self, batch ,batch_idx) -> STEP_OUTPUT:
        # print(batch.shape)
        i1, i2 = batch
        # print(i1.max())
        ms_ssim_out =  ms_ssim(i1,i2, data_range=1.0, size_average=False)
        print(ms_ssim_out)
        return ms_ssim_out
    
    def test_epoch_end(self, outputs) -> None:
        out_cos_sim =  torch.cat(outputs).cpu().numpy()
        np.savetxt(PHASE +'_mssim_out.csv', out_cos_sim)



model_pl = MSSSIM_Module(batch_size=BATCH_SIZE)
if METHOD == 'simclr':
    model_pl = SimCLR_pl(batch_size = BATCH_SIZE, max_epochs=EPOCHS, out_dir=PHASE)
    # model_pl = SimCLR_pl.load_from_checkpoint(CKPT_PATH, batch_size = BATCH_SIZE, max_epochs=EPOCHS)
elif METHOD == 'barlow':
    model_pl = BarlowTwins(encoder_out_dim=512,
    num_training_samples=len(all_set), batch_size = BATCH_SIZE, max_epochs=EPOCHS, out_dir=PHASE)
    # model_pl = BarlowTwins.load_from_checkpoint(CKPT_PATH, batch_size = BATCH_SIZE, max_epochs=EPOCHS)
elif METHOD == 'byol':
    model_pl = BYOL(encoder_out_dim=512, base_encoder=resnet18(), batch_size = BATCH_SIZE, max_epochs=EPOCHS, out_dir=PHASE)
    # model_pl = BYOL.load_from_checkpoint(CKPT_PATH, batch_size = BATCH_SIZE, out_dir=PHASE)
elif METHOD == 'simsiam':
    model_pl = SimSiam(encoder_out_dim=512, base_encoder=  resnet18(),batch_size = BATCH_SIZE, max_epochs=EPOCHS, out_dir=PHASE)
    # model_pl = SimSiam.load_from_checkpoint(CKPT_PATH, batch_size = BATCH_SIZE, out_dir=PHASE)



# if CKPT_LOAD:
#     model_pl = BarlowTwins.load_from_checkpoint(CKPT_PATH, batch_size = BATCH_SIZE, max_epochs=EPOCHS)

# checkpoint_callback = ModelCheckpoint(every_n_epochs=50, save_top_k= -1, save_last = True, mode="min", monitor="val_loss")

trainer = Trainer(enable_checkpointing=False, accelerator="auto", devices=1,  max_epochs=EPOCHS, logger=False)

# out = trainer.test(model_pl, all_loader, ckpt_path=CKPT_PATH)


out = trainer.test(model_pl, all_loader)


# val_outs = []
# test_outs = []
# train_outs = []

# with torch.no_grad():
#     # for val in tqdm(val_loader):
#     #     out = model_pl(val)['cos_sim']
#     #     val_outs.append(out)
    
#     # for test in tqdm(test_loader):
#     #     out = model_pl(test)['cos_sim']
#     #     test_outs.append(out)

#     for test in tqdm(all_loader):
#         out = model_pl(test)['cos_sim']
#         test_outs.append(out)



# if METHOD == 'mssim':
#     for im1, im2 in tqdm(all_loader):
#         out = ms_ssim(im1, im2)
#         print(out.shape)
#         outs.append(out)
#         # test_outs.append(out)
#     mssims = torch.cat(outs).cpu().numpy()
#     np.savetxt(PHASE+'_mssim_out.csv', mssims)



# model_pl = SimCLR_pl(BATCH_SIZE, max_epochs=EPOCHS)

# if CKPT_LOAD:

#     model_pl = SimCLR_pl.load_from_checkpoint(CKPT_PATH, batch_size = BATCH_SIZE, max_epochs=EPOCHS)

# import pandas as pd

# test_array = torch.cat(test_outs).cpu().numpy()
# test_df = test_set.get_header_df()
# print(test_array.shape)
# print(test_df.shape)

# test_df.loc[:, 'cosine_sim'] = test_array
# test_df.to_csv('simclr_all_transforms.csv')



# out = trainer.predict(model_pl, val_loader, ckpt_path=CKPT_PATH)

# trainer.fit(model_pl, datamodule=dm)



# import pandas as pd

# df = pd.DataFrame(outs)
# df.to_csv('simclr_outs_transform.csv')
# trainer.test(model_pl, test_loader, ckpt_path=CKPT_PATH)