# -*- coding: utf-8 -*-
"""AI Summer SimCLR Resnet18 STL10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LhKx8FPwn8GvLbiaOp3m2wZOPZE44tgZ

# SimCLR in STL10 with Resnet18 AI Summer tutorial

## Imports, basic utils, augmentations and Contrastive loss
"""

import torch
import os
from torch.multiprocessing import cpu_count

from simclr import reproducibility, SimCLR_pl

"""## Pretraining main logic"""
from pytorch_lightning import Trainer
from pytorch_lightning import seed_everything
from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor
from torchvision.models import  resnet18

from dataset import MIMIC_CXR_Dataset
from torch.utils.data import DataLoader
from pytorch_lightning import LightningDataModule

from simclr import SimCLRTestTransforms, SimCLRTrainTransforms


# ROOT = '/home/asim.ukaye/physionet.org/files/mimic-cxr-jpg/2.0.0/'

ROOT = '/home/asim.ukaye/ml_proj/mimic_cxr_pa_resized/'
EPOCHS = 1000
BATCH_SIZE = 128
NUM_WORKERS = 24

CKPT_LOAD = False
CKPT_PATH ='/home/asim.ukaye/ml_proj/simclr_cxr/lightning_logs/version_34/checkpoints/last.ckpt'

seed_everything(1256)

# dm = CXR_DataModule(ROOT, BATCH_SIZE, mode='train')

transforms = SimCLRTrainTransforms(img_size=224)
train_set = MIMIC_CXR_Dataset(ROOT, split='train',augmentations=transforms)
val_set = MIMIC_CXR_Dataset(ROOT, split='val', augmentations=transforms)

train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)
val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)


model_pl = SimCLR_pl(BATCH_SIZE, max_epochs=EPOCHS)

if CKPT_LOAD:
    model_pl.load_from_checkpoint(CKPT_PATH)

checkpoint_callback = ModelCheckpoint(every_n_epochs=50, save_top_k= -1, save_last = True, mode="min", monitor="val_loss")

trainer = Trainer(callbacks=[checkpoint_callback, LearningRateMonitor("epoch")], accelerator="auto", devices=1,  max_epochs=EPOCHS, resume_from_checkpoint=CKPT_PATH)


# trainer.fit(model_pl, datamodule=dm)
trainer.fit(model_pl, train_loader, val_loader)




# """## Save only backbone weights from Resnet18 that are only necessary for fine tuning"""

# model_pl = SimCLR_pl(BATCH_SIZE, model=resnet18(pretrained=True))
# model_pl = weights_update(model_pl, "SimCLR_ResNet18_adam_.ckpt")

# best_model = SimCLR_pl.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)
# resnet18_backbone_weights = best_model.model.backbone
# print(resnet18_backbone_weights)
# torch.save({
#             'model_state_dict': resnet18_backbone_weights.state_dict(),
#             }, 'resnet18_backbone_weights.ckpt')
